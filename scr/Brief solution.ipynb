{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a5da943-493b-46dd-b8bf-148ae7f9b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b226c-c5e9-4775-b456-4a04e858079a",
   "metadata": {},
   "source": [
    "# Задание №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74ad5ece-7b41-43ba-967d-36a1e86f6aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 * N\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_csv('../data/data_task4_old.txt', sep = '\\t', parse_dates = ['assigned_ts','closed_ts'])\n",
    "def data_prep(df):\n",
    "    df['delta_dt'] = (df['closed_ts'] - df['assigned_ts'])\n",
    "    df['delta'] = df['delta_dt'] / pd.Timedelta('1 second')\n",
    "    df['delta_for_one'] = round(df['delta'] / df['Microtasks'], 0)\n",
    "    df['delta_for_one_dt'] = (df['delta_dt'] / df['Microtasks']).dt.round('S')\n",
    "    return df\n",
    "df = data_prep(df_in)\n",
    "# Исключаем данные в кторых время выполнения оказалось меньше 0 \n",
    "df = df[df['delta'] > 0]\n",
    "top_quantile = .9998 # Явные выбросы\n",
    "df = df[df['delta_for_one'] < df['delta_for_one'].quantile(top_quantile)] # Удаляем выбросы\n",
    "delt = df.loc[: , 'delta_for_one']\n",
    "x_max = 600\n",
    "alfa = 3\n",
    "hist_1 = gaussian_filter1d(np.histogram(delt[df['Microtasks'] == 1], bins = range(x_max))[0], alfa)\n",
    "round_step = 5 \n",
    "fair_delta = round_step * math.ceil(np.argmax(hist_1)/round_step)\n",
    "print(round(fair_delta / 30, 1), '* N')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080e95c3-ebd7-452a-a53d-4d75b2843ae0",
   "metadata": {},
   "source": [
    "# Задание №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d76e7ae1-9424-467d-b14b-9711333ae762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответы приведены в порядке ухудшения качества работы ассеора\n",
      "\n",
      "Лучшие 10 асессоров:  [487, 596, 171, 184, 259, 545, 315, 217, 166, 570]\n",
      "Худшие 10 асессоров:  [157, 354, 112, 234, 390, 3, 56, 111, 118, 163]\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_csv('../data/data_task3.csv', \n",
    "                    sep = '\\t', \n",
    "                   )\n",
    "df_in['quality'] = (df_in['jud'] == df_in['cjud']).astype(int)\n",
    "df_docid = df_in[['docid', 'quality']].groupby(['docid']).mean().sort_values('quality')\n",
    "docid_list = df_docid[(df_docid['quality'] > 0)&(df_docid['quality'] < 1)].index\n",
    "def assessors_rating(df):\n",
    "    df_users = pd.DataFrame(index = df.uid.sort_values().unique())\n",
    "    for uid in df_users.index:\n",
    "        jud = df.loc[df['uid'] == uid, 'jud'] # Оценка асессора\n",
    "        cjud = df.loc[df['uid'] == uid, 'cjud'] # Верная оценка\n",
    "        df_users.loc[uid, 'accuracy_score'] = accuracy_score(jud, cjud) # Простой процент правильных ответов\n",
    "        df_users.loc[uid, 'f1_score'] = f1_score(jud, cjud) # f1 метрика полнота + качество\n",
    "        df_users.loc[uid, 'Count'] = df.loc[df['uid'] == uid, 'uid'].count()\n",
    "    #     break\n",
    "    return df_users.sort_values('f1_score', ascending = False)\n",
    "df_users = assessors_rating(df_in[df_in['docid'].isin(docid_list)])\n",
    "print('Ответы приведены в порядке ухудшения качества работы ассеора\\n')\n",
    "print('Лучшие 10 асессоров: ', list(df_users.index[:10]))\n",
    "print('Худшие 10 асессоров: ', list(df_users.index[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6c8c7-4681-47c5-8a84-c70646646c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
